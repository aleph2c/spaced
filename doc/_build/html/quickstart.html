
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Quick Start &#8212; spaced 0.1 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Recipes" href="recipes.html" />
    <link rel="prev" title="Introduction" href="introduction.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <blockquote>
<div><p><em>Any fool can know.  The point is to understand.</em></p>
<p class="attribution">&mdash;Albert Einstein</p>
</div></blockquote>
<div class="section" id="quick-start">
<span id="id1"></span><h1>Quick Start<a class="headerlink" href="#quick-start" title="Permalink to this headline">¶</a></h1>
<div class="section" id="getting-an-initial-schedule">
<span id="quickstart-getting-an-initial-schedule"></span><h2>Getting an Initial Schedule<a class="headerlink" href="#getting-an-initial-schedule" title="Permalink to this headline">¶</a></h2>
<p>To build a schedule, import a learning tracker and provide it with its initial
conditions:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">space.repitition</span> <span class="kn">import</span> <span class="n">pp</span>
<span class="kn">from</span> <span class="nn">space.repitition</span> <span class="kn">import</span> <span class="n">LearningTracker</span>

<span class="n">days_to_track</span> <span class="o">=</span> <span class="mi">43</span>  <span class="c1"># used for graphing</span>

<span class="n">lt</span> <span class="o">=</span> <span class="n">LearningTracker</span><span class="p">(</span>
  <span class="n">epoch</span><span class="o">=</span><span class="n">datetime</span><span class="o">.</span><span class="n">new</span><span class="p">(),</span>
  <span class="nb">range</span><span class="o">=</span><span class="n">days_to_track</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Then ask your learning tracker for its schedule:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;Scheduled as dates&quot;</span><span class="p">)</span>
<span class="n">pp</span><span class="p">(</span><span class="n">lt</span><span class="o">.</span><span class="n">schedule</span><span class="p">())</span>
</pre></div>
</div>
<p>Something like this would appear in your terminal window:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Scheduled as dates
[ datetime.datetime(2018, 12, 22, 4, 23, 42, 247300),
        datetime.datetime(2018, 12, 22, 15, 28, 53, 456841),
        datetime.datetime(2018, 12, 23, 4, 3, 40, 733013),
        datetime.datetime(2018, 12, 23, 19, 20, 14, 562054),
        datetime.datetime(2018, 12, 24, 15, 33, 37, 943760),
        datetime.datetime(2018, 12, 25, 22, 9, 53, 666487),
        datetime.datetime(2018, 12, 28, 9, 45, 48, 339845),
        datetime.datetime(2019, 1, 6, 9, 51, 41, 920278)]
</pre></div>
</div>
</div>
<div class="section" id="understanding-where-a-schedule-comes-from">
<span id="quickstart-understanding-where-a-schedule-comes-from"></span><h2>Understanding where a Schedule Comes from<a class="headerlink" href="#understanding-where-a-schedule-comes-from" title="Permalink to this headline">¶</a></h2>
<p>To see the graph from which this schedule was derived:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hdl</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">lt</span><span class="o">.</span><span class="n">reference</span><span class="o">.</span><span class="n">plot_graph</span><span class="p">()</span>
</pre></div>
</div>
<a class="reference external image-reference" href="_static/quickstart_reference.pdf"><div align="center" class="align-center"><img alt="_images/quickstart_reference.svg" src="_images/quickstart_reference.svg" /></div>
</a>
<p>The graph’s x-axis represents time while the y-axis represents the amount a
student can remember about the thing they are trying to learn. The student has
perfectly remembered an idea if its score is one and they have utterly forgotten
an idea if its score is zero.</p>
<p>The red stickleback looking graph represents how a students recollection ability
will rise and fall as a function of training events and the passage of time from
a given training event. At first, a student forgets something quickly, but as
they train on an idea, that idea will fade slower from their memory. The sudden
vertical-rise of this red line represents a moment when the student studies.
There is an assumption that they will review an idea long enough that their
immediate recollection of that idea will be perfect before they stop thinking
about it.</p>
<p>The blue line maps to <a class="reference external" href="https://en.wikipedia.org/wiki/Neuroplasticity">plasticity</a>, or how fast an idea can be
mapped into a mind as a function over time.  It can be thought of as
representing how memories form over the long term.</p>
<p>The training events occur where the forgetting curves of the stickleback
approach the plasticity line. At each intersection of the forgetting curve and
the plasticity curve, orange lines are projected downward to the x-axis to
provide the suggested times of study. Collectively, these times are called the
schedule.</p>
</div>
<div class="section" id="adding-student-feedback">
<span id="quickstart-adding-student-feedback"></span><h2>Adding Student Feedback<a class="headerlink" href="#adding-student-feedback" title="Permalink to this headline">¶</a></h2>
<p>To begin with the schedule is completely arbitrary.  This is because the model
doesn’t understand anything about the student yet.  But each time you give it
student data it adapts its schedule to the student’s behavior, and how they
appear to be forgetting things.</p>
<p>Imagine that immediately after looking at the material for the first time; our
student tries to remember what they just learned.  They determine that they can
recall about 40 percent of the material.  To tell <code class="docutils literal notranslate"><span class="pre">spaced</span></code> about this, we
would write the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">days_since_training_epoch</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">lt</span><span class="o">.</span><span class="n">learned</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">when</span><span class="o">=</span><span class="n">days_since_training_epoch</span><span class="p">)</span>
</pre></div>
</div>
<p>Immediately after finishing their test, the student reviews the material until
they understand all of it.</p>
<p>Suppose that 19 hours later (0.8 days later), the student tests themselves
again.  This time they can remember 44 percent of it.  Let’s feed this into the
learning tracker, by writing the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">days_since_training_epoch</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">lt</span><span class="o">.</span><span class="n">learned</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="mf">0.44</span><span class="p">,</span> <span class="n">when</span><span class="o">=</span><span class="n">days_since_training_epoch</span><span class="p">)</span>
</pre></div>
</div>
<p>As before, the student reviews the material until they have complete
understanding, immediately after they have tested themselves.</p>
</div>
<div class="section" id="getting-a-schedule-which-responds-to-the-student-s-feedback">
<span id="quickstart-getting-a-schedule-which-responds-to-the-student-s-feedback"></span><h2>Getting a Schedule which Responds to the Student’s Feedback<a class="headerlink" href="#getting-a-schedule-which-responds-to-the-student-s-feedback" title="Permalink to this headline">¶</a></h2>
<p>Now that <code class="docutils literal notranslate"><span class="pre">spaced</span></code> has more data, let’s ask it for its new schedule:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;Scheduled as dates&quot;</span><span class="p">)</span>
<span class="n">pp</span><span class="p">(</span><span class="n">lt</span><span class="o">.</span><span class="n">schedule</span><span class="p">())</span>
</pre></div>
</div>
<p>In your terminal you will see something like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Scheduled as dates
[ datetime.datetime(2018, 12, 23, 1, 53, 3, 865177),
        datetime.datetime(2018, 12, 23, 16, 32, 43, 271301),
        datetime.datetime(2018, 12, 24, 11, 49, 1, 151759),
        datetime.datetime(2018, 12, 25, 17, 9, 28, 362910),
        datetime.datetime(2018, 12, 28, 3, 57, 43, 777324),
        datetime.datetime(2019, 1, 7, 0, 21, 16, 69957),
        datetime.datetime(2018, 12, 21, 14, 0, 13, 200220),
        datetime.datetime(2018, 12, 22, 1, 26, 21, 259959),
        datetime.datetime(2018, 12, 22, 13, 46, 42, 422666),
        datetime.datetime(2018, 12, 23, 4, 26, 21, 828789),
        datetime.datetime(2018, 12, 23, 23, 42, 39, 709248),
        datetime.datetime(2018, 12, 25, 5, 3, 6, 920399),
        datetime.datetime(2018, 12, 27, 15, 51, 22, 334813),
        datetime.datetime(2019, 1, 6, 12, 14, 54, 627446)]
</pre></div>
</div>
</div>
<div class="section" id="understanding-the-reactive-schedule">
<span id="quickstart-understanding-the-reactive-schedule"></span><h2>Understanding the Reactive Schedule<a class="headerlink" href="#understanding-the-reactive-schedule" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">spaced</span></code> schedule changes as it reacts to feedback from the student. To
see why this change has occurred we can look at the plots from which this
schedule is derived:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hdl</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">lt</span><span class="o">.</span><span class="n">plot_graphs</span><span class="p">()</span>
</pre></div>
</div>
<a class="reference external image-reference" href="_static/quickstart_control_after_two_events.pdf"><img alt="_images/quickstart_control_after_two_events.png" class="align-center" src="_images/quickstart_control_after_two_events.png" /></a>
<p>The learning tracker diagram above contains four different graphs.  The first
graph is called the recommendation.  It represents the goal of our training
engagement with this student for the thing that they are trying to learn.  It is
exactly the same as the reference graph we plotted above.</p>
<p>The 2nd graph represents the observed data that the student has given us.  At
time zero they could remember 40 percent of an idea after their initial
training session.  They retrained, then retested themselves 0.8 days later and
got 44 percent. Then they retrained again.  The light blue line on the observed
curve is an analogue to the dark blue line on the recommendation curve.  It is
a plasticity curve, but unlike the reference-plasticity curve in the
recommendation graph, the observed-plasticity curve is discovered by fitting a
line to the data provided as feedback from the student.  It is describing how a
long term memory is actually forming in the student’s mind, not how we wish it
would be formed (represented by the dark blue line in the recommendation graph).</p>
<p>The 3rd graph down the page, labeled “error signal” is the difference between
what we want and what we got.  Specifically it is the difference between the
recommendation graphs plasticity curve and the observed plasticity curve (the
dark blue line in the first graph minus the light blue graph in the second graph).
The y-axis of this plot can be positive, if a memory isn’t forming as fast as we
want, or negative, if the student is studying too much or doesn’t really forget
things; causing a memory to form faster than our recommendation.</p>
<p>The final graph, the 4th graph, is labeled “control”.  This is because it
describes how the <code class="docutils literal notranslate"><span class="pre">spaced</span></code> algorithm tries to drive its error signal to zero
by controlling the world in the only way it can: by shifting its schedule
recommendations.  It does this in two ways, it tunes the forgetting curves (the
red stickleback lines) to match how a student actually forgets things and it
finds the intersection between the observed plasticity curve and the
reference-plasticity curve, then redraws the updated-forgetting-stickleback on
the reference-plasticity curve at this intersection point.</p>
<p>Lets see what happens if the student continues to train.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># students tests themselves 1.75 days after they start training</span>
<span class="c1"># they recall about 64 percent of the thing they are studying</span>
<span class="n">days_since_training_epoch</span> <span class="o">=</span> <span class="mf">1.75</span>
<span class="n">lt</span><span class="o">.</span><span class="n">learned</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="mf">0.64</span><span class="p">,</span> <span class="n">when</span><span class="o">=</span><span class="n">days_since_training_epoch</span><span class="p">)</span>
<span class="c1"># the student reviews their material until</span>
<span class="c1"># they have a perfect recollection</span>

<span class="c1"># students tests themselves 3.02 days after they start training</span>
<span class="c1"># they recall about 76 percent of the thing they are studying</span>
<span class="n">days_since_training_epoch</span> <span class="o">=</span> <span class="mf">3.02</span>
<span class="n">lt</span><span class="o">.</span><span class="n">learned</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="mf">0.76</span><span class="p">,</span> <span class="n">when</span><span class="o">=</span><span class="n">days_since_training_epoch</span><span class="p">)</span>
<span class="c1"># the student reviews their material until</span>
<span class="c1"># they have a perfect recollection</span>
</pre></div>
</div>
<a class="reference external image-reference" href="_static/quickstart_control_after_four_events.pdf"><img alt="_images/quickstart_control_after_four_events.png" class="align-center" src="_images/quickstart_control_after_four_events.png" /></a>
<p>Now suppose the student trains six more times:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">days_and_results</span> <span class="o">=</span> <span class="p">[</span>
  <span class="p">[</span><span class="mf">4.8</span><span class="p">,</span>  <span class="mf">7.33</span><span class="p">,</span> <span class="mf">10.93</span><span class="p">,</span> <span class="mf">16.00</span><span class="p">,</span> <span class="mf">23.00</span><span class="p">,</span> <span class="mf">29.00</span><span class="p">],</span>
  <span class="p">[</span><span class="mf">0.83</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">,</span>  <span class="mf">1.00</span><span class="p">,</span>  <span class="mf">0.99</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span>   <span class="mf">1.00</span><span class="p">],</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">d</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">days_and_results</span><span class="p">):</span>
  <span class="n">days_since_training_epoch</span><span class="p">,</span> <span class="n">result</span> <span class="o">=</span> <span class="n">d</span><span class="p">,</span> <span class="n">r</span>
  <span class="n">lt</span><span class="o">.</span><span class="n">learned</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="n">result</span><span class="p">,</span> <span class="n">when</span><span class="o">=</span><span class="n">days_since_training_epoch</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">lt</span><span class="o">.</span><span class="n">schedule</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2019</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="mi">192016</span><span class="p">)]</span>
</pre></div>
</div>
<p>Let’s take a look at the graph:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hdl</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">lt</span><span class="o">.</span><span class="n">plot_graphs</span><span class="p">()</span>
</pre></div>
</div>
<a class="reference external image-reference" href="_static/quickstart_control_after_ten_events.pdf"><img alt="_images/quickstart_control_after_ten_events.png" class="align-center" src="_images/quickstart_control_after_ten_events.png" /></a>
<p>This last graph really isn’t that useful: the next recommended training date
isn’t on its control plot.</p>
<p>In fact, it’s hard to get a clear idea about what is going on by looking at any
of these plots in isolation.  What is better is to flip through them one at a
time in sequential succession; in this way you can look at a plot while having
it’s history in your recent visual memory, so as to give it some context.</p>
<p>What would be nice would be an animation of each training event followed by the
next.  You could watch it for 10 seconds and get a good idea about their
training history.  The <code class="docutils literal notranslate"><span class="pre">spaced</span></code> library provides such an animation feature and
it is described in the next section.</p>
</div>
<div class="section" id="animating-the-reactive-schedule-to-get-an-intuitive-feeling-about-results">
<span id="quickstart-animating-reactive-schedule-to-get-an-intuitive-feel"></span><h2>Animating the Reactive Schedule to get an Intuitive Feeling about Results<a class="headerlink" href="#animating-the-reactive-schedule-to-get-an-intuitive-feeling-about-results" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">spaced</span></code> package can write <code class="docutils literal notranslate"><span class="pre">mp4</span></code> encoded videos using the <code class="docutils literal notranslate"><span class="pre">ffmpeg</span></code>
animation plugin provided by matplotlib.</p>
<p>To make a video, using the <code class="docutils literal notranslate"><span class="pre">animate</span></code> api:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">lt</span><span class="o">.</span><span class="n">animate</span><span class="p">(</span>
  <span class="n">student</span><span class="o">=</span><span class="s2">&quot;Name of Student&quot;</span><span class="p">,</span>
  <span class="n">name_of_mp4</span><span class="o">=</span><span class="s2">&quot;results/report_card.mp4&quot;</span><span class="p">,</span>
  <span class="n">time_per_event_in_seconds</span><span class="o">=</span><span class="mf">2.2</span><span class="p">)</span>
</pre></div>
</div>
<p>If you were to write this code, the results of this session would be used to
make a video in <code class="docutils literal notranslate"><span class="pre">results/report_card.mp4</span></code>.  That video would look something like this:</p>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/H8llYuwH5L0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center><p>As you play the video, you see a story unfold about the relationship between our
model and the student’s reaction to it. In the first five days of their
training, we see that they made more mistakes than we would have liked, then,
around the seventh day, something clicks for them, and they do better than what
was predicted by the original model.</p>
<p>We can see that the control system tried to get them to do much more training
when they were doing poorly, and less training when they started to understand
the material. When the dark blue reference curve in the control box moved to the
left, the student was doing better than expected, and when it shifted to the
right, the student was doing worse than expected.</p>
<p>We also see that our initial forgetting curves were too pessimistic, and as a
result our initial schedule was too aggressive. But after a few training events,
the spaced algorithm began to match the forgetting parameters to how the student
actually forgot things.</p>
<p>The video plays a training event every second, which means that we are
accelerating time since the training events become more and more spaced out the
later they occur.</p>
</div>
<div class="section" id="predicting-future-results">
<span id="quickstart-predicting-future-results"></span><h2>Predicting Future Results<a class="headerlink" href="#predicting-future-results" title="Permalink to this headline">¶</a></h2>
<p>But, it is unlikely that you will be using <code class="docutils literal notranslate"><span class="pre">spaced</span></code> to track just one object.  You
will probably have thousands of them running, and you will have to select from a
small subset of these thousands of tracked objects to compile a review session for your
student.  To do this, you need to know which of your tracked <code class="docutils literal notranslate"><span class="pre">spaced</span></code> objects
are in the most need of attention.</p>
<p>For this reason you will need to query a <code class="docutils literal notranslate"><span class="pre">spaced</span></code> object so that it can make a
prediction about a student’s ability to recall a fact at some datetime.  To predict
a result, you can use the learning tracker’s <code class="docutils literal notranslate"><span class="pre">predict_result</span></code> api.</p>
<p>To demonstrate this, I will make a set of predictions and graph them onto the
plot generated by the learning tracker.</p>
<p>Here is how to do this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">repetition</span> <span class="kn">import</span> <span class="n">pp</span>
<span class="kn">from</span> <span class="nn">repetition</span> <span class="kn">import</span> <span class="n">LearningTracker</span>

<span class="c1"># create a learning tracker</span>
<span class="n">lt</span> <span class="o">=</span> <span class="n">LearningTracker</span><span class="p">(</span>
    <span class="n">epoch</span><span class="o">=</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
<span class="p">)</span>

<span class="c1"># give our learning tracker some feedback</span>
<span class="k">for</span> <span class="n">d</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span>    <span class="mf">0.8</span><span class="p">,</span>  <span class="mf">1.75</span><span class="p">,</span> <span class="mf">3.02</span><span class="p">,</span> <span class="mf">4.8</span><span class="p">,</span>  <span class="mf">7.33</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.40</span><span class="p">,</span> <span class="mf">0.44</span><span class="p">,</span> <span class="mf">0.64</span><span class="p">,</span> <span class="mf">0.76</span><span class="p">,</span> <span class="mf">0.83</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">],</span>
  <span class="p">):</span>
  <span class="c1"># r: result</span>
  <span class="c1"># d: days since training epoch</span>
  <span class="n">lt</span><span class="o">.</span><span class="n">learned</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">when</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>

<span class="c1"># get a set of datetimes</span>
<span class="n">useful_range_of_datetimes</span> <span class="o">=</span> \
  <span class="n">lt</span><span class="o">.</span><span class="n">range_for</span><span class="p">(</span><span class="n">curve</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">day_step_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="c1"># make a results query using these datetimes</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">lt</span><span class="o">.</span><span class="n">predict_result</span><span class="p">(</span><span class="n">moment</span><span class="p">,</span> <span class="n">curve</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span>
            <span class="n">moment</span> <span class="ow">in</span> <span class="n">useful_range_of_datetimes</span><span class="p">]</span>
<span class="n">hdl</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">lt</span><span class="o">.</span><span class="n">plot_graphs</span><span class="p">()</span>

<span class="c1"># get the handle for the last subplot so we can draw on it</span>
<span class="n">control_plot</span> <span class="o">=</span> <span class="n">hdl</span><span class="o">.</span><span class="n">axarr</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">control_plot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
  <span class="n">useful_range_of_datetimes</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;xkcd:azure&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Here is the resulting plot:</p>
<a class="reference external image-reference" href="_static/quickstart_control_after_five_events_and_query.pdf"><div align="center" class="align-center"><img alt="_images/quickstart_control_after_five_events_and_query.svg" src="_images/quickstart_control_after_five_events_and_query.svg" /></div>
</a>
<p>You can see when we plot a set of queries for the results of the first learning
curve over a set of datetimes, that the line representing this information
extends downward past the plasticity line.  This is because the query assumes
that no additional training event will occur.</p>
</div>
<div class="section" id="building-a-better-initial-student-model">
<span id="quickstart-building-a-better-initial-student-model"></span><h2>Building a Better Initial Student Model<a class="headerlink" href="#building-a-better-initial-student-model" title="Permalink to this headline">¶</a></h2>
<p>As the <code class="docutils literal notranslate"><span class="pre">spaced</span></code> algorithm reacts to student feedback, it gets a much better
idea about how the student remembers and forgets in their current environment.
It’s control system tunes the forgetting and plasticity parameters as it tries
to build a better schedule.</p>
<p>Now imagine we let one learning tracker run for a while, then we pulled it’s
discovered parameters to create some initial conditions for another learning
tracker, one with a more realistic set of goals.  These goals would be based on
how a student has behaved in the past, instead of some imagined thing.</p>
<p>I’ll demonstrate how to do this, by first simulating a full training session (10
lessons) using the arbitrary default values of the <code class="docutils literal notranslate"><span class="pre">spaced</span></code> algorithm.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">repetition</span> <span class="kn">import</span> <span class="n">LearningTracker</span>

<span class="n">day_offset_from_epoch_and_results</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span>    <span class="mf">0.81</span><span class="p">,</span> <span class="mf">1.75</span><span class="p">,</span> <span class="mf">3.02</span><span class="p">,</span> <span class="mf">4.8</span><span class="p">,</span>  <span class="mf">8.33</span><span class="p">,</span> <span class="mf">10.93</span><span class="p">,</span> <span class="mf">16.00</span><span class="p">,</span> <span class="mf">23.00</span><span class="p">,</span> <span class="mf">29.00</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.40</span><span class="p">,</span> <span class="mf">0.44</span><span class="p">,</span> <span class="mf">0.64</span><span class="p">,</span> <span class="mf">0.84</span><span class="p">,</span> <span class="mf">0.83</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">,</span>  <span class="mf">1.00</span><span class="p">,</span>  <span class="mf">0.99</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span>   <span class="mf">1.00</span><span class="p">],</span>
<span class="p">]</span>

<span class="c1"># create a learning tracker with arbitrary default parameters</span>
<span class="n">lt_arbitrary</span> <span class="o">=</span> <span class="n">LearningTracker</span><span class="p">(</span>
  <span class="n">epoch</span><span class="o">=</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
<span class="p">)</span>

<span class="c1"># plot the third lesson so we can take a look at the differences</span>
<span class="c1"># between some made up model and a model based</span>
<span class="c1"># on some previous feedback</span>
<span class="n">lesson_to_graph</span> <span class="o">=</span> <span class="mi">3</span>

<span class="c1"># mimic a full training session</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span> <span class="ow">in</span> \
  <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">day_offset_from_epoch_and_results</span><span class="p">)):</span>
  <span class="c1"># r: result</span>
  <span class="c1"># d: days since training epoch</span>
  <span class="n">lt_arbitrary</span><span class="o">.</span><span class="n">learned</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">when</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>

  <span class="c1"># plot the lesson we want to graph</span>
  <span class="k">if</span> <span class="n">index</span> <span class="ow">is</span> <span class="n">lesson_to_graph</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">hdl</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">lt_arbitrary</span><span class="o">.</span><span class="n">plot_graphs</span><span class="p">()</span>
</pre></div>
</div>
<a class="reference external image-reference" href="_static/quickstart_arbitrary.pdf"><div align="center" class="align-center"><img alt="_images/quickstart_arbitrary.svg" src="_images/quickstart_arbitrary.svg" /></div>
</a>
<p>So what can we learn from this?</p>
<blockquote>
<div><p>1.  Our student forgets things slower than we expected:  The forgetting curves
in the recommendation plot are steeper than that seen in the feedback
plot.</p>
<p>2.  Our student is remembering the things slower than we wanted them to learn:  The error
signal is positive.</p>
</div></blockquote>
<p>Now lets build another learning tracker using the discovered parameters from
letting the first learning tracker run for ten lessons:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># get better initial model parameters based on previous</span>
<span class="c1"># experience with the student</span>

<span class="c1"># to get the discovered parameter from a previous training session,</span>
<span class="c1"># pre-pend &#39;discovered&#39; in front of the parameter name,</span>
<span class="c1"># and call this word like a function</span>
<span class="n">bpr</span> <span class="o">=</span> <span class="n">lt_arbitrary</span><span class="o">.</span><span class="n">discovered_plasticity_root</span><span class="p">()</span>
<span class="n">bpdo</span> <span class="o">=</span> <span class="n">lt_arbitrary</span><span class="o">.</span><span class="n">discovered_plasticity_denominator_offset</span><span class="p">()</span>
<span class="n">bf0</span> <span class="o">=</span> <span class="n">lt_arbitrary</span><span class="o">.</span><span class="n">discovered_fdecay0</span><span class="p">()</span>
<span class="n">bft</span> <span class="o">=</span> <span class="n">lt_arbitrary</span><span class="o">.</span><span class="n">discovered_fdecaytau</span><span class="p">()</span>

<span class="n">lt_better_fit</span> <span class="o">=</span> <span class="n">LearningTracker</span><span class="p">(</span>
  <span class="n">epoch</span><span class="o">=</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span>
  <span class="n">plasticity_root</span><span class="o">=</span><span class="n">bpr</span><span class="p">,</span>
  <span class="n">plasticity_denominator_offset</span><span class="o">=</span><span class="n">bpdo</span><span class="p">,</span>
  <span class="n">fdecay0</span><span class="o">=</span><span class="n">bf0</span><span class="p">,</span>
  <span class="n">fdecaytau</span><span class="o">=</span><span class="n">bft</span>
<span class="p">)</span>

<span class="c1"># plot the third lesson so we can take a look at the differences</span>
<span class="c1"># between some made up model and a model based</span>
<span class="c1"># on some previous feedback</span>
<span class="n">lesson_to_graph</span> <span class="o">=</span> <span class="mi">3</span>

<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span> <span class="ow">in</span> \
  <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">day_offset_from_epoch_and_results</span><span class="p">)):</span>
  <span class="c1"># r: result</span>
  <span class="c1"># d: days since training epoch</span>
  <span class="n">lt_better_fit</span><span class="o">.</span><span class="n">learned</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">when</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>

  <span class="c1"># plot the lesson we want to graph</span>
  <span class="k">if</span> <span class="n">index</span> <span class="ow">is</span> <span class="n">lesson_to_graph</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">lt_better_fit</span><span class="o">.</span><span class="n">plot_graphs</span><span class="p">()</span>
</pre></div>
</div>
<a class="reference external image-reference" href="_static/quickstart_better_fit.pdf"><div align="center" class="align-center"><img alt="_images/quickstart_better_fit.svg" src="_images/quickstart_better_fit.svg" /></div>
</a>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Try and pretend this plot is from real student feedback and not from a
conjured example.</p>
</div>
<p>We trust our recommendation curve more than we did when it was completely
arbitrary, so now what can we learn from this diagram?</p>
<p>Our eyes glance at how the forgetting curves on the recommendation graph and the
observed plot are falling at around the same rate.  This means that our model
seems realistic, letting us make some clearer inferences about the results of
the control plot.</p>
<p>The difference between what we want and what we got can be attributed to how the
student isn’t meticulously following the recommended schedule.  This is the
expected behavior, since the schedule could place training in the middle of the
night or at some other inconvenient time for the student.  It doesn’t matter if the
student religiously follows their schedule, since the schedule is adaptive.
What we want to see is if they are <em>kind of</em> following that schedule and if the
observed plasticity curve <em>kind of</em> looks like our reference plasticity curve; it
does.</p>
<p>Summary: our student seems to be on track.</p>
</div>
<div class="section" id="dealing-with-forgetting-over-the-long-term">
<span id="quickstart-dealing-with-forgetting-over-the-long-term"></span><h2>Dealing with Forgetting Over the Long Term<a class="headerlink" href="#dealing-with-forgetting-over-the-long-term" title="Permalink to this headline">¶</a></h2>
<p>What happens to a schedule after an idea has been mastered?  To answer this we
must first ask a different question, what happens to a memory after it has been
mastered over the first couple of months?</p>
<p>Your memories are reliant on physical three dimensional chemical-electrical
circuits in your brain tissue.  These circuits are built up as a pattern of
neuron and glial cells.  The neurons connect in such a way that their pattern
will offer up the memory when it is stimulated by an electrical impulse – this
impulse being a kind of query from another part of your mind.  The electrical
wave front propagating out from your memory’s neural cluster offers-up what
feels like knowledge, and recollection in your conscious awareness.</p>
<p>The transmission of these memory wave fronts through the brain make memories
holonomic:  A memory exists in all parts of the brain all at once.  This is
because a network can have multiple patterns imprinted on them at the same time,
and a pattern is imprinted when a network experiences a wave front.</p>
<p>Think about how sand organizes itself on a beach in reaction to a wave.  It, and
its adjacent particles flow with the wave front, only to re-settle into a stable
state once the watery part of the wave subsides back into the ocean.  Every wave
will move the sand, but the sand mostly stays in the same location over time.</p>
<p>We have large craniums, but they are not infinite, the real-estate in the brain
is limited, and if a specific network pattern is not being used it could be
pruned back; its volume, resources and cells commandeered to map another memory.
Your brain organizes its neurons using adversarial competition, so if a memory
network doesn’t have a signature that expresses utility, it could very well be
cannibalized to map another set of ideas.  At least it looks this way from the
outside.  Maybe all that is happening is that the sand on that part of the beach
has been re-organized by many many different thoughts, many different
wave-fronts impressing their patterns onto that patch of sand.</p>
<p>This process is largely passive, mysterious and outside of our conscious
control.  The brain’s pruning and plasticity mechanism can’t determine what you
think of as being consciously important; they use an emergent recipe brought to
us by evolution, it optimizes for your survival; it is based on emotional
queues, when the network was fired last, where a network is situated in the
brain, not to mention many other factors.</p>
<p>To save a trained skill, and its neural pattern from oblivion, we need to
activate it from time to time.  This will not guarantee that you won’t lose your
hard-fought memory, but it will reduce the probability of its destruction.</p>
<p>So, this is just a really complicated way of saying that we have to think about
the thing we understand to hold off the brain’s garbage collector.</p>
<p>We have to activate a network even after it has been mastered.  This can happen
very infrequently, and it can be thought of as a kind of maintenance pulse.</p>
<p>To see how this works with the <code class="docutils literal notranslate"><span class="pre">spaced</span></code> library consider the following
example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">start_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="c1"># track for 2 years</span>
<span class="n">range_in_days</span> <span class="o">=</span> <span class="mi">365</span><span class="o">*</span><span class="mi">2</span>

<span class="n">lt</span> <span class="o">=</span> <span class="n">LearningTracker</span><span class="p">(</span>
  <span class="n">epoch</span><span class="o">=</span><span class="n">start_time</span><span class="p">,</span>
  <span class="nb">range</span><span class="o">=</span><span class="n">range_in_days</span><span class="p">,</span>
  <span class="n">long_term_clamp</span><span class="o">=</span><span class="mf">0.00005</span><span class="p">,</span>  <span class="c1"># default</span>
<span class="p">)</span>

<span class="c1"># the idea is mastered over two months</span>
<span class="n">day_offset_from_epoch_and_results</span> <span class="o">=</span> <span class="p">[</span>
  <span class="p">[</span><span class="mi">0</span><span class="p">,</span>    <span class="mf">0.81</span><span class="p">,</span> <span class="mf">1.75</span><span class="p">,</span> <span class="mf">3.02</span><span class="p">,</span> <span class="mf">4.8</span><span class="p">,</span>  <span class="mf">8.33</span><span class="p">,</span> <span class="mf">16.00</span><span class="p">,</span> <span class="mf">23.00</span><span class="p">,</span> <span class="mf">29.00</span><span class="p">,</span> <span class="mi">60</span><span class="p">],</span>
  <span class="p">[</span><span class="mf">0.40</span><span class="p">,</span> <span class="mf">0.44</span><span class="p">,</span> <span class="mf">0.64</span><span class="p">,</span> <span class="mf">0.84</span><span class="p">,</span> <span class="mf">0.83</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">,</span>  <span class="mf">0.99</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span>   <span class="mf">0.90</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">],</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">d</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">day_offset_from_epoch_and_results</span><span class="p">)</span>
  <span class="c1"># r: result</span>
  <span class="c1"># d: days since training epoch</span>
  <span class="n">lt</span><span class="o">.</span><span class="n">learned</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">when</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>

<span class="c1"># look at the schedule over two years</span>
<span class="n">hdl</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">lt</span><span class="o">.</span><span class="n">plot_graphs</span><span class="p">()</span>
</pre></div>
</div>
<p>We create feedback for 60 days and look at the schedule recommendations provided
by <code class="docutils literal notranslate"><span class="pre">spaced</span></code> for two years:</p>
<a class="reference external image-reference" href="_static/quickstart_long_term.pdf"><img alt="_images/quickstart_long_term.svg" src="_images/quickstart_long_term.svg" /></a>
<p>You can see the maintenance pulses are just schedule suggestions over the longer
term. The schedule is sparse immediately after mastery then it tightens up more
and more into the future.</p>
<p>Doesn’t this mean that as time progresses, spaced will annoy the student with
maintenance reviews?</p>
<p>To answer this question, I will first have to provide more context. There will
be a lot of spaced learning trackers for each student in a system. As a student
adds more items to their education, in aggregate, their learning tracker’s
schedule suggestions will cause a kind of attention-jam. The student can only
look at so much per review without being exhausted. So the system will have to
ignore some schedule suggestions, or the system will stop working as it scales.</p>
<p>The client code using spaced will query each of the objects and select a subset
of them which are in most need of maintenance, then it will use these items for
the review. Well, this is almost true.</p>
<p>The client code will run a kind of lottery, where each of the learning trackers
will get one or more lottery tickets. The number of lottery tickets given to
each tracker will be proportional to how bad their student’s memory will be at
the moment of the review. In this way, young, weaker memories, will get more
tickets. After the tickets are assigned, the client runs a lottery. The number
of draws in each lottery will be proportional to how much attention a student
can put into their review. The learning trackers with the winning tickets will
win the student’s attention.</p>
<p>Or, in more technical language, the client code will have a sampler who’s
probability distribution is distorted by the query results, such that it will
have a bias to select things that are about to be forgotten.</p>
<p>After a student has mastered an idea being tracked with a learning tracker, its
forgetting curves remain mostly flat, so a query made against it in the
maintenance pulse part of its schedule, will return a value very close to one.
A learning tracker’s in their maintenance phase won’t be given very many lottery
tickets.</p>
<p>So when you look at the above curve, and it’s schedule, you can think of these
times as moments a geriatric memory is given a single lottery ticket, in a
lottery that is rigged for youthful memories.</p>
<p>What happens if a geriatric memory wins a lottery and gets into a review? Well,
it will stop trying to get tickets for a while, you can see this in on the above graph
at 2019-04. The time between review suggestions swells a bit.  Then a pressure
will build again and it will try to get into more and more lotteries (but the
client will only give it one ticket).</p>
<a class="reference internal" href="introduction.html"<span class="std-ref">prev</span></a>, <a class="reference internal" href="index.html#top"><span class="std std-ref">top</span></a>, <a class="reference internal" href="recipes.html"><span class="std std-ref">next</span></a><div class="toctree-wrapper compound">
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><p class="logo"><a href="index.html">
  <img class="logo_a" src="_static/spaced_1.svg" width="250" alt="Logo" >
</a></p>
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Quick Start</a><ul>
<li><a class="reference internal" href="#getting-an-initial-schedule">Getting an Initial Schedule</a></li>
<li><a class="reference internal" href="#understanding-where-a-schedule-comes-from">Understanding where a Schedule Comes from</a></li>
<li><a class="reference internal" href="#adding-student-feedback">Adding Student Feedback</a></li>
<li><a class="reference internal" href="#getting-a-schedule-which-responds-to-the-student-s-feedback">Getting a Schedule which Responds to the Student’s Feedback</a></li>
<li><a class="reference internal" href="#understanding-the-reactive-schedule">Understanding the Reactive Schedule</a></li>
<li><a class="reference internal" href="#animating-the-reactive-schedule-to-get-an-intuitive-feeling-about-results">Animating the Reactive Schedule to get an Intuitive Feeling about Results</a></li>
<li><a class="reference internal" href="#predicting-future-results">Predicting Future Results</a></li>
<li><a class="reference internal" href="#building-a-better-initial-student-model">Building a Better Initial Student Model</a></li>
<li><a class="reference internal" href="#dealing-with-forgetting-over-the-long-term">Dealing with Forgetting Over the Long Term</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="introduction.html" title="previous chapter">Introduction</a></li>
      <li>Next: <a href="recipes.html" title="next chapter">Recipes</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/quickstart.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Scott Volk.
      
      |
      <a href="_sources/quickstart.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>